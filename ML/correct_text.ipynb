{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "id": "GvSN1J85dfCB",
    "outputId": "b2176ac7-66cc-4db1-e60d-921197e3fc36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 533.2MB 28kB/s \n",
      "\u001b[K     |████████████████████████████████| 460kB 43.0MB/s \n",
      "\u001b[K     |████████████████████████████████| 2.8MB 50.7MB/s \n",
      "\u001b[K     |████████████████████████████████| 2.9MB 63.3MB/s \n",
      "\u001b[K     |████████████████████████████████| 778kB 64.7MB/s \n",
      "\u001b[31mERROR: tensorflow 1.15.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[?25h179727\n",
      "20273\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d10cd6cfe3da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n\u001b[0;32m---> 61\u001b[0;31m     (en.numpy() for en,pt in train_dataset), target_vocab_size=2**13)\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mtokenizer_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mtokenizer_pt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer_en\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2034\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIteratorV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n\u001b[0m\u001b[1;32m    344\u001b[0m                          \"or when eager execution is enabled.\")\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: __iter__() is only supported inside of tf.function or when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import datetime\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "  !pip install -q tf-nightly \n",
    "except Exception:\n",
    "  pass\n",
    "dataset=[]\n",
    "#print(tf.__version__)\n",
    "file='../../dataset/translate-dataset/'\n",
    "file='./drive/My Drive/correct_dataset/'\n",
    "source_token='./drive/My Drive/correct_dataset/source'\n",
    "target_token='./drive/My Drive/correct_dataset/target'\n",
    "train_dataset=[]\n",
    "train_target=[]\n",
    "val_dataset=[]\n",
    "val_target=[]\n",
    "test_dataset=[]\n",
    "test_target=[]\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = './drive/My Drive/correct_dataset/' + current_time + '/train'\n",
    "test_log_dir = './drive/My Drive/correct_dataset/' + current_time + '/test'\n",
    "train_summary_writer = tf.compat.v2.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.compat.v2.summary.create_file_writer(test_log_dir)\n",
    "with open(file+'training_set.txt') as f:\n",
    "    for each in f.readlines():\n",
    "        if each[:4]== 'src:':\n",
    "            train_dataset.append(each[4:])\n",
    "            #print(\"1\"+each[4:])\n",
    "        else:\n",
    "            train_target.append(each[4:])\n",
    "            #print(\"2\"+each[4:])\n",
    "    print(len(train_dataset))\n",
    "with open(file +'val_set.txt') as f:\n",
    "    for each in f.readlines():\n",
    "        if each[:4] == 'src:':\n",
    "            test_dataset.append(each[4:])\n",
    "        else:\n",
    "            test_target.append(each[4:])\n",
    "\n",
    "    print(len(test_dataset))\n",
    "\n",
    "\n",
    "\n",
    "train_dataset=tf.data.Dataset.from_tensor_slices((train_dataset,train_target))\n",
    "test_dataset=tf.data.Dataset.from_tensor_slices((test_dataset,test_target))\n",
    "#val_dataset=tf.data.Dataset.from_tensor_slices((val_dataset,val_target))\n",
    "\n",
    "\n",
    "\"\"\"从训练数据集创建自定义子词分词器（subwords tokenizer）。\"\"\"\n",
    "if os.path.exists(source_token):\n",
    "    tokenizer_en=tfds.features.text.SubwordTextEncoder.load_from_file(source_token)\n",
    "else:\n",
    "    tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for en,pt in train_dataset), target_vocab_size=2**13)\n",
    "    tokenizer_en.save_to_file(source_token)\n",
    "tokenizer_pt=tokenizer_en\n",
    "\"\"\"if os.path.exists(target_token):\n",
    "    tokenizer_pt=tfds.features.text.SubwordTextEncoder.load_from_file(target_token)\n",
    "else:\n",
    "    tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for en,pt in train_dataset), target_vocab_size=2 ** 13)\n",
    "    tokenizer_pt.save_to_file(target_token)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"如果单词不在词典中，则分词器（tokenizer）通过将单词分解为子词来对字符串进行编码。\"\"\"\n",
    "\n",
    "\n",
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "\"\"\"将开始和结束标记（token）添加到输入和目标。\"\"\"\n",
    "\n",
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "        lang1.numpy()) + [tokenizer_pt.vocab_size + 1]\n",
    "\n",
    "    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "        lang2.numpy()) + [tokenizer_en.vocab_size + 1]\n",
    "\n",
    "    return lang1, lang2\n",
    "\n",
    "\n",
    "\"\"\"Note：为了使本示例较小且相对较快，删除长度大于40个标记的样本。\"\"\"\n",
    "\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "\n",
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length,\n",
    "                          tf.size(y) <= max_length)\n",
    "\n",
    "\n",
    "\"\"\"`.map()` 内部的操作以图模式（graph mode）运行，`.map()` 接收一个不具有 numpy 属性的图张量（graph tensor）。该`分词器（tokenizer）`需要将一个字符串或 Unicode 符号，编码成整数。因此，您需要在 `tf.py_function` 内部运行编码过程，`tf.py_function` 接收一个 eager 张量，该 eager 张量有一个包含字符串值的 numpy 属性。\"\"\"\n",
    "\n",
    "\n",
    "def tf_encode(en,pt):\n",
    "    return tf.py_function(encode, [en,pt], [tf.int64, tf.int64])\n",
    "\n",
    "#val_dataset=val_dataset.map(tf_encode)\n",
    "test_dataset=test_dataset.map(tf_encode)\n",
    "train_dataset = train_dataset.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# 将数据集缓存到内存中以加快读取速度。\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_dataset=test_dataset.filter(filter_max_length).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
    "#val_dataset = val_dataset.filter(filter_max_length).padded_batch(\n",
    "#    BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
    "\n",
    "test_dataset=test_dataset.cache()\n",
    "#val_dataset=val_dataset.cache()\n",
    "\n",
    "\n",
    "\"\"\"## 位置编码（Positional encoding）\n",
    "\n",
    "因为该模型并不包括任何的循环（recurrence）或卷积，所以模型添加了位置编码，为模型提供一些关于单词在句子中相对位置的信息。\n",
    "\n",
    "位置编码向量被加到嵌入（embedding）向量中。嵌入表示一个 d 维空间的标记，在 d 维空间中有着相似含义的标记会离彼此更近。但是，嵌入并没有对在一句话中的词的相对位置进行编码。因此，当加上位置编码后，词将基于*它们含义的相似度以及它们在句子中的位置*，在 d 维空间中离彼此更近。\n",
    "\n",
    "参看 [位置编码](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) 的 notebook 了解更多信息。计算位置编码的公式如下：\n",
    "\n",
    "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
    "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "\n",
    "    # 将 sin 应用于数组中的偶数索引（indices）；2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # 将 cos 应用于数组中的奇数索引；2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"## 遮挡（Masking）\n",
    "\n",
    "遮挡一批序列中所有的填充标记（pad tokens）。这确保了模型不会将填充作为输入。该 mask 表明填充值 `0` 出现的位置：在这些位置 mask 输出 `1`，否则输出 `0`。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # 添加额外的维度来将填充加到\n",
    "    # 注意力对数（logits）。\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "\n",
    "\"\"\"前瞻遮挡（look-ahead mask）用于遮挡一个序列中的后续标记（future tokens）。换句话说，该 mask 表明了不应该使用的条目。\n",
    "\n",
    "这意味着要预测第三个词，将仅使用第一个和第二个词。与此类似，预测第四个词，仅使用第一个，第二个和第三个词，依此类推。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "\n",
    "\"\"\"## 按比缩放的点积注意力（Scaled dot product attention）\n",
    "\n",
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
    "\n",
    "Transformer 使用的注意力函数有三个输入：Q（请求（query））、K（主键（key））、V（数值（value））。用于计算注意力权重的等式为：\n",
    "\n",
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
    "\n",
    "点积注意力被缩小了深度的平方根倍。这样做是因为对于较大的深度值，点积的大小会增大，从而推动 softmax 函数往仅有很小的梯度的方向靠拢，导致了一种很硬的（hard）softmax。\n",
    "\n",
    "例如，假设 `Q` 和 `K` 的均值为0，方差为1。它们的矩阵乘积将有均值为0，方差为 `dk`。因此，*`dk` 的平方根*被用于缩放（而非其他数值），因为，`Q` 和 `K` 的矩阵乘积的均值本应该为 0，方差本应该为1，这样会获得一个更平缓的 softmax。\n",
    "\n",
    "遮挡（mask）与 -1e9（接近于负无穷）相乘。这样做是因为遮挡与缩放的 Q 和 K 的矩阵乘积相加，并在 softmax 之前立即应用。目标是将这些单元归零，因为 softmax 的较大负数输入在输出中接近于零。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"计算注意力权重。\n",
    "    q, k, v 必须具有匹配的前置维度。\n",
    "    k, v 必须有匹配的倒数第二个维度，例如：seq_len_k = seq_len_v。\n",
    "    虽然 mask 根据其类型（填充或前瞻）有不同的形状，\n",
    "    但是 mask 必须能进行广播转换以便求和。\n",
    "\n",
    "    参数:\n",
    "      q: 请求的形状 == (..., seq_len_q, depth)\n",
    "      k: 主键的形状 == (..., seq_len_k, depth)\n",
    "      v: 数值的形状 == (..., seq_len_v, depth_v)\n",
    "      mask: Float 张量，其形状能转换成\n",
    "            (..., seq_len_q, seq_len_k)。默认为None。\n",
    "\n",
    "    返回值:\n",
    "      输出，注意力权重\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # 缩放 matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # 将 mask 加入到缩放的张量上。\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        # softmax 在最后一个轴（seq_len_k）上归一化，因此分数\n",
    "    # 相加等于1。\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights\n",
    "\n",
    "\n",
    "\"\"\"当 softmax 在 K 上进行归一化后，它的值决定了分配到 Q 的重要程度。\n",
    "\n",
    "输出表示注意力权重和 V（数值）向量的乘积。这确保了要关注的词保持原样，而无关的词将被清除掉。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "\n",
    "# 这条 `请求（query）符合第二个`主键（key）`，\n",
    "# 因此返回了第二个`数值（value）`。\n",
    "\n",
    "\n",
    "\"\"\"## 多头注意力（Multi-head attention）\n",
    "\n",
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n",
    "\n",
    "\n",
    "多头注意力由四部分组成：\n",
    "*    线性层并分拆成多头。\n",
    "*    按比缩放的点积注意力。\n",
    "*    多头及联。\n",
    "*    最后一层线性层。\n",
    "\n",
    "每个多头注意力块有三个输入：Q（请求）、K（主键）、V（数值）。这些输入经过线性（Dense）层，并分拆成多头。 \n",
    "\n",
    "将上面定义的 `scaled_dot_product_attention` 函数应用于每个头（进行了广播（broadcasted）以提高效率）。注意力这步必须使用一个恰当的 mask。然后将每个头的注意力输出连接起来（用`tf.transpose` 和 `tf.reshape`），并放入最后的 `Dense` 层。\n",
    "\n",
    "Q、K、和 V 被拆分到了多个头，而非单个的注意力头，因为多头允许模型共同注意来自不同表示空间的不同位置的信息。在分拆后，每个头部的维度减少，因此总的计算成本与有着全部维度的单个注意力头相同。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"分拆最后一个维度到 (num_heads, depth).\n",
    "        转置结果使得形状为 (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention,\n",
    "                                        perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "\n",
    "\n",
    "\"\"\"创建一个 `MultiHeadAttention` 层进行尝试。在序列中的每个位置 `y`，`MultiHeadAttention` 在序列中的所有其他位置运行所有8个注意力头，在每个位置y，返回一个新的同样长度的向量。\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"## 点式前馈网络（Point wise feed forward network）\n",
    "\n",
    "点式前馈网络由两层全联接层组成，两层之间有一个 ReLU 激活函数。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "\n",
    "\"\"\"## 编码与解码（Encoder and decoder）\n",
    "\n",
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">\n",
    "\n",
    "Transformer 模型与标准的[具有注意力机制的序列到序列模型（sequence to sequence with attention model）](nmt_with_attention.ipynb)，遵循相同的一般模式。\n",
    "\n",
    "* 输入语句经过 `N` 个编码器层，为序列中的每个词/标记生成一个输出。\n",
    "* 解码器关注编码器的输出以及它自身的输入（自注意力）来预测下一个词。\n",
    "\n",
    "### 编码器层（Encoder layer）\n",
    "\n",
    "每个编码器层包括以下子层：\n",
    "\n",
    "1.   多头注意力（有填充遮挡）\n",
    "2.   点式前馈网络（Point wise feed forward networks）。\n",
    "\n",
    "每个子层在其周围有一个残差连接，然后进行层归一化。残差连接有助于避免深度网络中的梯度消失问题。\n",
    "\n",
    "每个子层的输出是 `LayerNorm(x + Sublayer(x))`。归一化是在 `d_model`（最后一个）维度完成的。Transformer 中有 N 个编码器层。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n",
    "\n",
    "\n",
    "# (batch_size, input_seq_len, d_model)\n",
    "\n",
    "\"\"\"### 解码器层（Decoder layer）\n",
    "\n",
    "每个解码器层包括以下子层：\n",
    "\n",
    "1.   遮挡的多头注意力（前瞻遮挡和填充遮挡）\n",
    "2.   多头注意力（用填充遮挡）。V（数值）和 K（主键）接收*编码器输出*作为输入。Q（请求）接收*遮挡的多头注意力子层的输出*。\n",
    "3.   点式前馈网络\n",
    "\n",
    "每个子层在其周围有一个残差连接，然后进行层归一化。每个子层的输出是 `LayerNorm(x + Sublayer(x))`。归一化是在 `d_model`（最后一个）维度完成的。\n",
    "\n",
    "Transformer 中共有 N 个解码器层。\n",
    "\n",
    "当 Q 接收到解码器的第一个注意力块的输出，并且 K 接收到编码器的输出时，注意力权重表示根据编码器的输出赋予解码器输入的重要性。换一种说法，解码器通过查看编码器输出和对其自身输出的自注意力，预测下一个词。参看按比缩放的点积注意力部分的演示。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training,\n",
    "             look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"### 编码器（Encoder）\n",
    "\n",
    "`编码器` 包括：\n",
    "1.   输入嵌入（Input Embedding）\n",
    "2.   位置编码（Positional Encoding）\n",
    "3.   N 个编码器层（encoder layers）\n",
    "\n",
    "输入经过嵌入（embedding）后，该嵌入与位置编码相加。该加法结果的输出是编码器层的输入。编码器的输出是解码器的输入。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
    "                                                self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # 将嵌入和位置编码相加。\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"### 解码器（Decoder）\n",
    "\n",
    "`解码器`包括：\n",
    "1.   输出嵌入（Output Embedding）\n",
    "2.   位置编码（Positional Encoding）\n",
    "3.   N 个解码器层（decoder layers）\n",
    "\n",
    "目标（target）经过一个嵌入后，该嵌入和位置编码相加。该加法结果是解码器层的输入。解码器的输出是最后的线性层的输入。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training,\n",
    "             look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                   look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"## 创建 Transformer\n",
    "\n",
    "Transformer 包括编码器，解码器和最后的线性层。解码器的输出是线性层的输入，返回线性层的输出。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask,\n",
    "             look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights\n",
    "\n",
    "\n",
    "\"\"\"## 配置超参数（hyperparameters）\n",
    "\n",
    "为了让本示例小且相对较快，已经减小了*num_layers、 d_model 和  dff* 的值。 \n",
    "\n",
    "Transformer 的基础模型使用的数值为：*num_layers=6*，*d_model = 512*，*dff = 2048*。关于所有其他版本的 Transformer，请查阅[论文](https://arxiv.org/abs/1706.03762)。\n",
    "\n",
    "Note：通过改变以下数值，您可以获得在许多任务上达到最先进水平的模型。\n",
    "\"\"\"\n",
    "\n",
    "num_layers =6\n",
    "d_model = 512\n",
    "dff = 2048\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1\n",
    "\n",
    "\"\"\"## 优化器（Optimizer）\n",
    "\n",
    "根据[论文](https://arxiv.org/abs/1706.03762)中的公式，将 Adam 优化器与自定义的学习速率调度程序（scheduler）配合使用。\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "\n",
    "\"\"\"## 损失函数与指标（Loss and metrics）\n",
    "\n",
    "由于目标序列是填充（padded）过的，因此在计算损失函数时，应用填充遮挡非常重要。\n",
    "\"\"\"\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n",
    "\n",
    "\"\"\"## 训练与检查点（Training and checkpointing）\"\"\"\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size,\n",
    "                          pe_input=input_vocab_size,\n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)\n",
    "\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    # 编码器填充遮挡\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # 在解码器的第二个注意力模块使用。\n",
    "    # 该填充遮挡用于遮挡编码器的输出。\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # 在解码器的第一个注意力模块使用。\n",
    "    # 用于填充（pad）和遮挡（mask）解码器获取到的输入的后续标记（future tokens）。\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "\n",
    "\"\"\"创建检查点的路径和检查点管理器（manager）。这将用于在每 `n` 个周期（epochs）保存检查点。\"\"\"\n",
    "\n",
    "checkpoint_path = file+\"/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# 如果检查点存在，则恢复最新的检查点。\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored!!')\n",
    "\n",
    "\"\"\"目标（target）被分成了 tar_inp 和 tar_real。tar_inp 作为输入传递到解码器。`tar_real` 是位移了 1 的同一个输入：在 `tar_inp` 中的每个位置，`tar_real` 包含了应该被预测到的下一个标记（token）。\n",
    "\n",
    "例如，`sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "Transformer 是一个自回归（auto-regressive）模型：它一次作一个部分的预测，然后使用到目前为止的自身的输出来决定下一步要做什么。\n",
    "\n",
    "在训练过程中，本示例使用了 teacher-forcing 的方法（就像[文本生成教程](./text_generation.ipynb)中一样）。无论模型在当前时间步骤下预测出什么，teacher-forcing 方法都会将真实的输出传递到下一个时间步骤上。\n",
    "\n",
    "当 transformer 预测每个词时，*自注意力（self-attention）*功能使它能够查看输入序列中前面的单词，从而更好地预测下一个单词。\n",
    "\n",
    "为了防止模型在期望的输出上达到峰值，模型使用了前瞻遮挡（look-ahead mask）。\n",
    "\"\"\"\n",
    "\n",
    "EPOCHS = 101\n",
    "\n",
    "# 该 @tf.function 将追踪-编译 train_step 到 TF 图中，以便更快地\n",
    "# 执行。该函数专用于参数张量的精确形状。为了避免由于可变序列长度或可变\n",
    "# 批次大小（最后一批次较小）导致的再追踪，使用 input_signature 指定\n",
    "# 更多的通用形状。\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def test_step(inp,tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "\n",
    "    predictions, _ = transformer(inp, tar_inp,\n",
    "                                     True,\n",
    "                                     enc_padding_mask,\n",
    "                                     combined_mask,\n",
    "                                     dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp,\n",
    "                                     True,\n",
    "                                     enc_padding_mask,\n",
    "                                     combined_mask,\n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)\n",
    "\n",
    "\"\"\"葡萄牙语作为输入语言，英语为目标语言。\"\"\"\n",
    "\n",
    "\"\"\"葡萄牙语作为输入语言，英语为目标语言。\"\"\"\n",
    "mini_loss=100\n",
    "num_loss=0\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    # inp -> portuguese, tar -> english\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print('Saving checkpoint for epoch {} at {}'.format(epoch + 1,\n",
    "                                                            ckpt_save_path))\n",
    "\n",
    "    print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n",
    "                                                        train_loss.result(),\n",
    "                                                        train_accuracy.result()))\n",
    "\n",
    "    print('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    for (batch, (inp, tar)) in enumerate(test_dataset):\n",
    "        test_step(inp, inp)\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "    if train_loss.result()<min_loss:\n",
    "        min_loss=train_loss.result()\n",
    "        num_loss=0\n",
    "    else:\n",
    "        num_loss=num_loss+1\n",
    "\n",
    "    print(' Test Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n",
    "                                                              train_loss.result(),\n",
    "                                                              train_accuracy.result()))\n",
    "\n",
    "    print('Time taken for 1 test epoch: {} secs\\n'.format(time.time() - start))\n",
    "    if num_loss>5:\n",
    "        break\n",
    "\"\"\"## 评估（Evaluate）\n",
    "\n",
    "以下步骤用于评估：\n",
    "\n",
    "* 用葡萄牙语分词器（`tokenizer_pt`）编码输入语句。此外，添加开始和结束标记，这样输入就与模型训练的内容相同。这是编码器输入。\n",
    "* 解码器输入为 `start token == tokenizer_en.vocab_size`。\n",
    "* 计算填充遮挡和前瞻遮挡。\n",
    "* `解码器`通过查看`编码器输出`和它自身的输出（自注意力）给出预测。\n",
    "* 选择最后一个词并计算它的 argmax。\n",
    "* 将预测的词连接到解码器输入，然后传递给解码器。\n",
    "* 在这种方法中，解码器根据它预测的之前的词预测下一个。\n",
    "\n",
    "Note：这里使用的模型具有较小的能力以保持相对较快，因此预测可能不太正确。要复现论文中的结果，请使用全部数据集，并通过修改上述超参数来使用基础 transformer 模型或者 transformer XL。\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"在本教程中，您已经学习了位置编码，多头注意力，遮挡的重要性以及如何创建一个 transformer。\n",
    "\n",
    "尝试使用一个不同的数据集来训练 transformer。您可也可以通过修改上述的超参数来创建基础 transformer 或者 transformer XL。您也可以使用这里定义的层来创建 [BERT](https://arxiv.org/abs/1810.04805) 并训练最先进的模型。此外，您可以实现 beam search 得到更好的预测。\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5aIP9RUlGBS"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yy_G2lt6ka0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "p4rXeugrv7lL",
    "outputId": "4b51f6be-5fa9-401a-be5d-382e398e9661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "H-WBIcK7eooC",
    "outputId": "46fe3365-0d1d-493d-f414-846862df0a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0.]]]], shape=(1, 1, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a=[1,2]\n",
    "b=tf.expand_dims(a,0)\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # 添加额外的维度来将填充加到\n",
    "    # 注意力对数（logits）。\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "res=create_padding_mask(b)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QjTdHLGwerBS",
    "outputId": "72f9678c-2762-4cac-d31f-218e8167fc27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: this is problem we have to solve .\n",
      "Predicted translation: this is problem we have to solve . .problem we have to solve .success . . . .\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate(inp_sentence):\n",
    "    start_token = [tokenizer_pt.vocab_size]\n",
    "    end_token = [tokenizer_pt.vocab_size + 1]\n",
    "\n",
    "    # 输入语句是葡萄牙语，增加开始和结束标记\n",
    "    inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "    # 因为目标是英语，输入 transformer 的第一个词应该是\n",
    "    # 英语的开始标记。\n",
    "    decoder_input = [tokenizer_en.vocab_size]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    train_accuracy.reset_states()\n",
    "    for i in range(MAX_LENGTH):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input,\n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # 从 seq_len 维度选择最后一个词\n",
    "        \n",
    "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 如果 predicted_id 等于结束标记，就返回结果\n",
    "        if predicted_id == tokenizer_en.vocab_size + 1:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        # 连接 predicted_id 与输出，作为解码器的输入传递到解码器。\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "    result=output\n",
    "    '''\n",
    "    print(encoder_input)\n",
    "    paddings=tf.constant([[0,0],[0,MAX_LENGTH-encoder_input.get_shape().as_list()[1]+1]])\n",
    "    print(paddings)\n",
    "    encoder_input=tf.pad(encoder_input,paddings,mode='CONSTANT')\n",
    "    print(output,encoder_input)\n",
    "    output=tf.expand_dims(output,0)\n",
    "    print\n",
    "    train_accuracy(encoder_input,output)\n",
    "    loss=loss_function(encoder_input,output)\n",
    "        \n",
    "    print(\"acc:{},loss:{}\",train_accuracy,loss)\n",
    "    '''\n",
    "    return tf.squeeze(result, axis=0), attention_weights\n",
    "\n",
    "\n",
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    sentence = tokenizer_pt.encode(sentence)\n",
    "\n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "\n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head + 1)\n",
    "\n",
    "        # 画出注意力权重\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence) + 2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result) - 1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>'] + [tokenizer_pt.decode([i]) for i in sentence] + ['<end>'],\n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result\n",
    "                            if i < tokenizer_en.vocab_size],\n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head + 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "\n",
    "    predicted_sentence = tokenizer_en.decode([i for i in result\n",
    "                                              if i < tokenizer_en.vocab_size])\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "\n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"## 总结\"\"\"\n",
    "num=0\n",
    "translate(\"this is problem we have to solve .\")\n",
    "with open(file+\"test.txt\",'w') as f:\n",
    "    for each in train_target:\n",
    "      result,_=evaluate(each)\n",
    "      predicted_sentence = tokenizer_en.decode([i for i in result\n",
    "                                              if i < tokenizer_en.vocab_size])\n",
    "\n",
    "      f.writelines(each)\n",
    "      f.writelines(predicted_sentence)\n",
    "      print(num)\n",
    "      num=num+1\n",
    "      if num ==100:\n",
    "        break\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "tUhQZ-YnunzY",
    "outputId": "24f2f103-b8d6-424a-983a-4aeeca973b26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.0.0b1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
      "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.0.dev2019060501)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
      "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.0a20190603)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (45.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "iDpeEEt7Fp7u",
    "outputId": "7f6afd32-ba51-4cdc-a13a-de0fd28bd405"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nv3KEJ8oFwdD",
    "outputId": "7b18e533-39b3-4761-8749-57cbda386866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 13 02:23:00 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gSMzvjHS2CQG",
    "outputId": "3b6b56fb-68aa-4a40-93d8-c9e825f65d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-13 02:23:57--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘aclImdb_v1.tar.gz’\n",
      "\n",
      "aclImdb_v1.tar.gz   100%[===================>]  80.23M  55.5MB/s    in 1.4s    \n",
      "\n",
      "2021-01-13 02:23:58 (55.5 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zqrSeJY8jHbR",
    "outputId": "bf992ce0-a589-4cfe-ff7d-0234d0ada23c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train files: 25000\n",
      "read test files: 25000\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 380, 32)           121600    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 380, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 129,345\n",
      "Trainable params: 129,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "200/200 - 5s - loss: 0.4886 - accuracy: 0.7517 - val_loss: 0.3881 - val_accuracy: 0.8122\n",
      "Epoch 2/10\n",
      "200/200 - 4s - loss: 0.2711 - accuracy: 0.8899 - val_loss: 0.3614 - val_accuracy: 0.8416\n",
      "Epoch 3/10\n",
      "200/200 - 4s - loss: 0.2310 - accuracy: 0.9082 - val_loss: 0.3613 - val_accuracy: 0.8484\n",
      "Epoch 4/10\n",
      "200/200 - 4s - loss: 0.2057 - accuracy: 0.9215 - val_loss: 0.3727 - val_accuracy: 0.8314\n",
      "Epoch 5/10\n",
      "200/200 - 4s - loss: 0.1816 - accuracy: 0.9303 - val_loss: 0.5058 - val_accuracy: 0.8146\n",
      "Epoch 6/10\n",
      "200/200 - 4s - loss: 0.1780 - accuracy: 0.9315 - val_loss: 0.4521 - val_accuracy: 0.8438\n",
      "Epoch 7/10\n",
      "200/200 - 4s - loss: 0.1636 - accuracy: 0.9373 - val_loss: 0.4009 - val_accuracy: 0.8538\n",
      "Epoch 8/10\n",
      "200/200 - 4s - loss: 0.1472 - accuracy: 0.9435 - val_loss: 0.5329 - val_accuracy: 0.8134\n",
      "Epoch 9/10\n",
      "200/200 - 4s - loss: 0.1318 - accuracy: 0.9503 - val_loss: 0.5342 - val_accuracy: 0.8348\n",
      "Epoch 10/10\n",
      "200/200 - 4s - loss: 0.1327 - accuracy: 0.9485 - val_loss: 0.4273 - val_accuracy: 0.8616\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 7s 8ms/step - loss: 0.4034 - accuracy: 0.8652\n",
      "[0.9900332]\n",
      "[0.00769656]\n",
      "[0.0042432]\n",
      "[0.7617404]\n",
      "[0.03312397]\n",
      "[0.20990895]\n",
      "[0.00792131]\n",
      "[0.00729761]\n",
      "[0.78378636]\n",
      "[0.14973794]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I liked this film a lot. The actors were great, particularly Potente, who is different in every role; Fürmann, who is also able to play anyone; and Loos, who spices things up (she is also a talented singer - she sings the song \"My Truth\", heard when one character cranks up the stereo in the lab).Anatomie is a good horror flick, which pays attention to its characters. It is also very gory at times, and the set design is innovative. It is too bad they had to make a sequel, which is nowhere near the original.On a side note, two other things definitely worth mentioning. The DVD is not dubbed, which makes for a better experience of the film. Also, make sure to keep watching after the final credits start rolling.\n",
      "label真实值: 正面的 预测结果: 正面的\n",
      "\"Plots With A View\" of 2002 is a delightful little comedy like only the British could do it. The film's sense of humor is both mildly morbid and black and yet very lovable and sometimes very slapstick-ish. It's the only film by director Nick Hurran I've seen so far, and while I am not intending to watch any of his other films at the moment (I'm not a big fan of romantic comedies), this one is highly enjoyable and very funny. The film takes place in a little town in Wales, where Betty Rhys-Jones (Brenda Blethyn) is married to the town's drunken and adulterous major (Robert Pugh). The local mortician Boris (Alfred Molina) has been desperately in love with Betty since their childhood, but has always been too shy to confess his love to her. Apart from being desperately in love, Boris has some other problems, as the eccentric American mortician Frank Featherbed (Christopher Walken) has opened a funeral flourishing business in the same town... The film's odd, very British wit should amuse everybody with a sense of humor, and the story sometimes becomes quite bizarre. Also, \"Plots With A View\" profits from a wonderful cast. Brenda Bethlyn, who has already proved herself to be a funny lady in 2000's \"Saving Grace\", plays the lead, and she is once again very funny, and very lovable in her role. Alfred Molina, who plays her shy admirer, delivers a great performance as always, and Robert Pugh fits perfectly in the role of Betty's sleazy husband. Beautiful Naomi Watts is also great as the husband's 'secretary', I'm becoming a bigger fan with every film I see her in. The greatest role, however, is played by the incomparable Christopher Walken (one of my favorite actors). Walken is brilliant as he always is in the role of the eccentric Mortician who arranges funerals that are quite unorthodox. Overall, \"Plots With A View\" is a vastly entertaining little British Comedy that I highly recommend!\n",
      "label真实值: 正面的 预测结果: 正面的\n",
      "The mission to see the movie \"The Cave\" was a dream of a friend of mine after witnessing the highly dramatic trailer, full of flashes of a creature lurking in a cave, some young cave divers, and not much else. It's too bad that the movie didn't change much more than the trailer did.The immediate allure of a movie like this is the creature. What's he going to look like? Why does he live in a cave? How is this one supposed to be different from the other creatures we've been shown in movies like Alien and Predator and the Relic? The cave \"demons\" do not look far from the skeletal creature in Alien: Resurrection and even has the sight of Predator. Shame that's a total ripoff...Well, let's look at the plot: very confusing and jumps to more and more totally improbable twists as a team of cave divers is sent to find a cave and its dwellers in the Carpathian Mountains. The casting was very much clear that we want young, hip, tough chicks, chiseled guys, and the girls who have brains also have to be hot. We also have to have one of every racial background in case the audience thinks that the film-makers are biased to a certain viewpoint. Totally been done, and I'm totally tired of it.The other main problem was the ending, as if to say there might be a sequel. Plase shoot me if there is one. The tagged on ending made me wretch.I gave this movie 3/10 stars. The points that it did get were more or less appreciation points towards the creature-builders for their high-quality job spent on the costuming and design for the monsters who dwell within, even when they looked totally ripped off. And there's an interesting (yet labored) documentary on the DVD on underwater cave diving. Go check it out only if you love new creations of monsters and creatures, but be warned that you've probably seen this movie before, and it was better the first time.\n",
      "label真实值: 负面的 预测结果: 负面的\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n'负面的'\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import re\n",
    "re_tag = re.compile(r'<[^>]+>')\n",
    " \n",
    "def rm_tags(text):\n",
    "    return re_tag.sub('', text)\n",
    " \n",
    "import os\n",
    "def read_files(filetype):\n",
    "    path = \"./aclImdb/\"\n",
    "    file_list=[]\n",
    " \n",
    "    positive_path=path + filetype+\"/pos/\"\n",
    "    for f in os.listdir(positive_path):\n",
    "        file_list+=[positive_path+f]\n",
    "    \n",
    "    negative_path=path + filetype+\"/neg/\"\n",
    "    for f in os.listdir(negative_path):\n",
    "        file_list+=[negative_path+f]\n",
    "        \n",
    "    print('read',filetype, 'files:',len(file_list))\n",
    "       \n",
    "    all_labels = ([1] * 12500 + [0] * 12500) \n",
    "    \n",
    "    all_texts  = []\n",
    "    \n",
    "    for fi in file_list:\n",
    "        with open(fi,encoding='utf8') as file_input:\n",
    "            all_texts += [rm_tags(\" \".join(file_input.readlines()))]\n",
    "            \n",
    "    return np.array(all_labels),np.array(all_texts)\n",
    " \n",
    "y_train,train_text=read_files(\"train\")\n",
    "y_test,test_text=read_files(\"test\")\n",
    "token = Tokenizer(num_words=3800)\n",
    "token.fit_on_texts(train_text)\n",
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq  = token.texts_to_sequences(test_text)\n",
    "x_train = sequence.pad_sequences(x_train_seq, maxlen=380)\n",
    "x_test  = sequence.pad_sequences(x_test_seq,  maxlen=380)\n",
    " \n",
    "#####建立模型\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    " \n",
    "model = Sequential()\n",
    " \n",
    "model.add(Embedding(output_dim=32,\n",
    "                    input_dim=3800, \n",
    "                    input_length=380))\n",
    "model.add(Dropout(0.35))\n",
    " \n",
    "model.add(LSTM(units=16))\n",
    " \n",
    "model.add(Dense(units=256,activation='relu' ))\n",
    " \n",
    "model.add(Dropout(0.35))\n",
    " \n",
    "model.add(Dense(units=1,activation='sigmoid' ))\n",
    " \n",
    "model.summary()\n",
    " \n",
    "#####训练模型\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    " \n",
    "train_history =model.fit(x_train, y_train,batch_size=100, \n",
    "                         epochs=10,verbose=2,\n",
    "                         validation_split=0.2)\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    " \n",
    "show_train_history(train_history,'accuracy','val_accuracy')\n",
    "show_train_history(train_history,'loss','val_loss')\n",
    " \n",
    "#####评估模型的准确率\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "scores[1]\n",
    " \n",
    "#####预测概率\n",
    "probility=model.predict(x_test)\n",
    "probility[:10]\n",
    " \n",
    "for p in probility[12500:12510]:\n",
    "    print(p)\n",
    " \n",
    "#####预测结果\n",
    "predict=model.predict_classes(x_test)\n",
    " \n",
    "predict[:10]\n",
    "predict.shape\n",
    "predict_classes=predict.reshape(25000)\n",
    "predict_classes\n",
    " \n",
    "#####查看预测结果\n",
    "SentimentDict={1:'正面的',0:'负面的'}\n",
    "def display_test_Sentiment(i):\n",
    "    print(test_text[i])\n",
    "    print('label真实值:',SentimentDict[y_test[i]],\n",
    "          '预测结果:',SentimentDict[predict_classes[i]])\n",
    " \n",
    "display_test_Sentiment(2)\n",
    " \n",
    "display_test_Sentiment(3)\n",
    "predict_classes[12500:12510]\n",
    "display_test_Sentiment(12502)\n",
    "'''\n",
    "注：以下是程序输出（不包括此句）\n",
    "First of all I hate those moronic rappers, who could'nt act if they had a gun pressed against their foreheads. All they do is curse and shoot each other and acting like cliché'e version of gangsters.The movie doesn't take more than five minutes to explain what is going on before we're already at the warehouse There is not a single sympathetic character in this movie, except for the homeless guy, who is also the only one with half a brain.Bill Paxton and William Sadler are both hill billies and Sadlers character is just as much a villain as the gangsters. I did'nt like him right from the start.The movie is filled with pointless violence and Walter Hills specialty: people falling through windows with glass flying everywhere. There is pretty much no plot and it is a big problem when you root for no-one. Everybody dies, except from Paxton and the homeless guy and everybody get what they deserve.The only two black people that can act is the homeless guy and the junkie but they're actors by profession, not annoying ugly brain dead rappers.Stay away from this crap and watch 48 hours 1 and 2 instead. At lest they have characters you care about, a sense of humor and nothing but real actors in the cast.\n",
    "label真实值: 负面的 预测结果: 负面的\n",
    "'''\n",
    " \n",
    "#预测新的影评\n",
    "input_text='''\n",
    "I can't vote because I have not watched this movie yet. I've been wanting to watch this movie since the time they announced making it which is about 2 years ago (!)\n",
    "I was planning to go with the family to see the anticipated movie but my nieces had school exams at the opening time so we all decided to wait for the next weekend. I was utterly shocked to learn yesterday that they pulled the movie from the Kuwaiti theaters \"temporarily\" so that the outrageous censorship system can remove some unwanted scenes.\n",
    "The controversial gay \"moment\" according to my online research is barely there, so I can't find any logical reason for all the fuss that's been going on. And it was bad enough when fanatics and haters tried (in vain) to kill the movie with low ratings and negative reviews even before it was in the cinemas and I'm pretty sure most of those trolls never got the chance to watch the movie at that time.\n",
    "Based on the trailers, I think the movie is very promising and entertaining and you can't simply overlook the tremendous efforts made to bring this beloved tale to life. To knock down hundreds of people's obvious hard work with unprofessional critique and negative reviews just for the sake of hatred is unfathomable. I hope people won't judge a movie before having the experience of watching it in the first place.\n",
    "Impatiently waiting for the Kuwaiti cinemas to bring back the movie... \n",
    "'''\n",
    "input_seq = token.texts_to_sequences([input_text])\n",
    "pad_input_seq  = sequence.pad_sequences(input_seq , maxlen=380)\n",
    "predict_result=model.predict_classes(pad_input_seq)\n",
    "SentimentDict[predict_result[0][0]]\n",
    "'''\n",
    "'负面的'\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MypZITejTsP"
   },
   "source": [
    "# 新段落"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "correct_text",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
